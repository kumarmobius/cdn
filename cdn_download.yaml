name: CDN Download Files
description: |
  Downloads trained_model.pt, config.properties, and tokenizer.json files from given CDN URLs
  and saves them locally with verified directory structure and file integrity checks.

inputs:
  - {name: pt_url, type: String, description: "URL to fetch the trained_model.pt model file from"}
  - {name: config_url, type: String, description: "URL to fetch the config.properties file from"}
  - {name: tokenizer_url, type: String, description: "URL to fetch the tokenizer.json file from"}

outputs:
  - {name: pt_file, type: Model, description: "Downloaded trained_model.pt model file"}
  - {name: config_file, type: String, description: "Downloaded config.properties file"}
  - {name: tokenizer_file, type: Model, description: "Downloaded tokenizer.json file"}

implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - sh
      - -c
      - |
        set -e
        echo "Installing dependencies..."
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet requests || \
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet requests --user
        exec python3 -u - "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import os
        import requests
        import sys

        CHUNK_SIZE = 16 * 1024

        parser = argparse.ArgumentParser()
        parser.add_argument('--pt_url', type=str, required=True)
        parser.add_argument('--pt_file', type=str, required=True)
        parser.add_argument('--config_url', type=str, required=True)
        parser.add_argument('--config_file', type=str, required=True)
        parser.add_argument('--tokenizer_url', type=str, required=True)
        parser.add_argument('--tokenizer_file', type=str, required=True)
        args = parser.parse_args()

        def safe_makedirs_for_file(path):
            d = os.path.dirname(path) or "."
            os.makedirs(d, exist_ok=True)

        def download_stream(url, out_path, timeout=300):
            print(f"Downloading {url} -> {out_path}")
            safe_makedirs_for_file(out_path)
            try:
                with requests.get(url, stream=True, timeout=timeout) as r:
                    r.raise_for_status()
                    total = 0
                    with open(out_path, "wb") as f:
                        for chunk in r.iter_content(chunk_size=CHUNK_SIZE):
                            if chunk:
                                f.write(chunk)
                                total += len(chunk)
                print(f"Saved {out_path} ({total} bytes)")
                return total
            except requests.exceptions.RequestException as e:
                print(f"Network error while downloading {url}: {e}")
                raise

        try:
            print("pt_url:", args.pt_url)
            print("config_url:", args.config_url)
            print("tokenizer_url:", args.tokenizer_url)

            # Download model
            download_stream(args.pt_url, args.pt_file, timeout=600)

            # Download config
            download_stream(args.config_url, args.config_file, timeout=120)

            # Download tokenizer
            download_stream(args.tokenizer_url, args.tokenizer_file, timeout=120)

            # Verify all
            for fpath, label in [
                (args.pt_file, "PT model"),
                (args.config_file, "Config file"),
                (args.tokenizer_file, "Tokenizer file"),
            ]:
                if not (os.path.exists(fpath) and os.path.getsize(fpath) > 0):
                    print(f"Error: {label} missing or empty: {fpath}")
                    sys.exit(1)
                else:
                    print(f"Verified {label}: {fpath} ({os.path.getsize(fpath)} bytes)")

            print("All files downloaded and verified successfully.")

        except Exception as e:
            print(" Error during download:", str(e))
            import traceback
            traceback.print_exc()
            sys.exit(1)
    args:
      - --pt_url
      - {inputValue: pt_url}
      - --pt_file
      - {outputPath: pt_file}
      - --config_url
      - {inputValue: config_url}
      - --config_file
      - {outputPath: config_file}
      - --tokenizer_url
      - {inputValue: tokenizer_url}
      - --tokenizer_file
      - {outputPath: tokenizer_file}
